"""
RAG (Retrieval-Augmented Generation) Service
RAG æª¢ç´¢å¢å¼·ç”Ÿæˆæœå‹™

Provides document retrieval and context injection for AI responses.
"""

import logging
from typing import List, Dict, Optional, Any
from django.db.models import Q

logger = logging.getLogger('analyst.rag')


def get_relevant_documents(
    user_id: str,
    query: str,
    max_docs: int = 3,
    min_relevance: float = 0.1
) -> List[Dict[str, Any]]:
    """
    Retrieve relevant documents for a query.
    æª¢ç´¢èˆ‡æŸ¥è©¢ç›¸é—œçš„æ–‡ä»¶ã€‚
    
    Uses keyword matching and document metadata to find relevant context.
    
    Args:
        user_id: The user's ID for filtering documents
        query: The search query
        max_docs: Maximum number of documents to return
        min_relevance: Minimum relevance score (0-1)
    
    Returns:
        List of relevant document summaries with context
    """
    try:
        from ai_assistants.models import AIDocument
        
        # Tokenize query into keywords
        query_lower = query.lower()
        keywords = [w for w in query_lower.split() if len(w) > 2]
        
        # Build query filter
        # Filter by user or public documents
        base_query = Q(uploaded_by_id=user_id) | Q(tags__contains=['public'])
        
        # Text search filter
        text_filter = Q()
        for keyword in keywords[:10]:  # Limit keywords
            text_filter |= (
                Q(title__icontains=keyword) |
                Q(extracted_text__icontains=keyword) |
                Q(ai_summary__icontains=keyword) |
                Q(ai_keywords__contains=[keyword])
            )
        
        if not text_filter:
            return []
        
        # Query documents
        documents = AIDocument.objects.filter(
            base_query & text_filter,
            is_active=True,
            extracted_text__isnull=False,
        ).order_by('-created_at')[:max_docs * 2]  # Get more, then score
        
        # Score and filter documents
        results = []
        for doc in documents:
            score = calculate_relevance_score(doc, keywords)
            
            if score >= min_relevance:
                results.append({
                    'id': str(doc.id),
                    'title': doc.title,
                    'document_type': doc.document_type,
                    'summary': doc.ai_summary[:500] if doc.ai_summary else '',
                    'keywords': doc.ai_keywords[:10] if doc.ai_keywords else [],
                    'excerpt': get_relevant_excerpt(doc.extracted_text, keywords),
                    'relevance_score': score,
                    'created_at': doc.created_at.isoformat(),
                })
        
        # Sort by relevance and limit
        results.sort(key=lambda x: x['relevance_score'], reverse=True)
        return results[:max_docs]
        
    except Exception as e:
        logger.error(f"Error retrieving documents: {e}")
        return []


def calculate_relevance_score(doc, keywords: List[str]) -> float:
    """
    Calculate relevance score for a document.
    è¨ˆç®—æ–‡ä»¶çš„ç›¸é—œæ€§åˆ†æ•¸ã€‚
    """
    score = 0.0
    
    title_lower = doc.title.lower()
    text_lower = (doc.extracted_text or '').lower()
    summary_lower = (doc.ai_summary or '').lower()
    doc_keywords = [k.lower() for k in (doc.ai_keywords or [])]
    
    for keyword in keywords:
        # Title match (highest weight)
        if keyword in title_lower:
            score += 0.3
        
        # Keyword match
        if keyword in doc_keywords:
            score += 0.25
        
        # Summary match
        if keyword in summary_lower:
            score += 0.2
        
        # Text match (lower weight due to noise)
        if keyword in text_lower:
            score += 0.1
    
    # Normalize by keyword count
    if keywords:
        score = score / len(keywords)
    
    return min(score, 1.0)  # Cap at 1.0


def get_relevant_excerpt(text: str, keywords: List[str], max_length: int = 300) -> str:
    """
    Extract a relevant excerpt from text.
    å¾æ–‡æœ¬ä¸­æå–ç›¸é—œæ‘˜è¦ã€‚
    """
    if not text:
        return ''
    
    text_lower = text.lower()
    
    # Find the best starting position
    best_pos = 0
    best_score = 0
    
    for i, keyword in enumerate(keywords):
        pos = text_lower.find(keyword)
        if pos != -1:
            # Score based on keyword importance (earlier keywords more important)
            score = 1 / (i + 1)
            if score > best_score:
                best_score = score
                best_pos = max(0, pos - 50)  # Start slightly before keyword
    
    # Extract excerpt
    excerpt = text[best_pos:best_pos + max_length]
    
    # Clean up - don't cut in the middle of words
    if best_pos > 0 and excerpt and excerpt[0] != ' ':
        space_pos = excerpt.find(' ')
        if space_pos > 0 and space_pos < 20:
            excerpt = excerpt[space_pos + 1:]
    
    if len(text) > best_pos + max_length:
        last_space = excerpt.rfind(' ')
        if last_space > max_length - 50:
            excerpt = excerpt[:last_space] + '...'
    
    return excerpt.strip()


def build_rag_context(
    user_id: str,
    query: str,
    max_docs: int = 3
) -> str:
    """
    Build RAG context string for AI prompt.
    æ§‹å»ºç”¨æ–¼ AI æç¤ºçš„ RAG ä¸Šä¸‹æ–‡ã€‚
    
    Args:
        user_id: User ID for document filtering
        query: The user's query
        max_docs: Maximum documents to include
    
    Returns:
        Formatted context string for AI prompt
    """
    documents = get_relevant_documents(user_id, query, max_docs)
    
    if not documents:
        return ""
    
    context_parts = ["\n--- ç›¸é—œæ–‡ä»¶åƒè€ƒ / Relevant Document References ---\n"]
    
    for i, doc in enumerate(documents, 1):
        context_parts.append(f"\nğŸ“„ æ–‡ä»¶ {i}: {doc['title']}")
        context_parts.append(f"   é¡å‹: {doc['document_type']}")
        
        if doc['summary']:
            context_parts.append(f"   æ‘˜è¦: {doc['summary'][:200]}...")
        
        if doc['excerpt']:
            context_parts.append(f"   ç›¸é—œå…§å®¹: ...{doc['excerpt']}...")
        
        if doc['keywords']:
            context_parts.append(f"   é—œéµå­—: {', '.join(doc['keywords'][:5])}")
    
    context_parts.append("\n--- çµæŸåƒè€ƒæ–‡ä»¶ / End References ---\n")
    
    return '\n'.join(context_parts)


def enhance_query_with_rag(
    user_id: str,
    query: str,
    data_context: str = "",
    max_docs: int = 3
) -> str:
    """
    Enhance the system prompt with RAG context.
    ä½¿ç”¨ RAG ä¸Šä¸‹æ–‡å¢å¼·ç³»çµ±æç¤ºã€‚
    """
    rag_context = build_rag_context(user_id, query, max_docs)
    
    if not rag_context:
        return data_context
    
    return f"{data_context}\n\n{rag_context}\n\nè«‹åœ¨å›ç­”æ™‚åƒè€ƒä»¥ä¸Šæ–‡ä»¶å…§å®¹ï¼ˆå¦‚æœç›¸é—œï¼‰ã€‚"
